{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5e223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "\n",
    "parent_dir = os.path.abspath('../../')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from utils.heatmap import generate_multi_gaussian_heatmaps, decode_heatmaps\n",
    "from utils.image_handling import crop_image, pad_bbox\n",
    "from utils.keypoints import crop_and_resize_keypoints\n",
    "from utils.evaluation import compute_add, compute_adds, compute_mde, compute_pck, compute_reprojection_error, estimate_pose_pnp, estimate_pose_pnp_ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee1fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6422c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model\n",
    "def load_yolo_model(model_path):\n",
    "    model = YOLO(model_path)\n",
    "    return model\n",
    "\n",
    "# Run YOLO inference\n",
    "def run_yolo_inference(model, image_path):\n",
    "    results = model(image_path, verbose=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671ae1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = BASE_PATH / \"models/yolo/yolo-lm.pt\"   \n",
    "yolo_model = load_yolo_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64291c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize(image, bbox, target_size):\n",
    "    # Crop the image using the bounding box\n",
    "    x, y, w, h = pad_bbox(bbox)\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "    # Resize the cropped image to the target size\n",
    "    resized_image = cv2.resize(cropped_image, (target_size[0], target_size[1]))\n",
    "\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "085b3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path,obj_id, fallback):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Run inference\n",
    "    results = yolo_model.predict(source=image, classes=[obj_id-1], conf=0.8, save=False, verbose=False)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "    if len(boxes) > 0:\n",
    "        x1, y1, x2, y2 = boxes[0]\n",
    "        x = int(x1)\n",
    "        y = int(y1)\n",
    "        w = int(x2)-x\n",
    "        h = int(y2)-y\n",
    "        crop_resized = crop_image(image, (x, y, w, h))\n",
    "        crop_tensor = torch.from_numpy(crop_resized.astype(np.float32) / 255.0).permute(2, 0, 1).unsqueeze(0)\n",
    "        bbox = (x, y, w, h)\n",
    "        return crop_tensor,  bbox\n",
    "    else:\n",
    "        cropped_img = crop_image(image, fallback)\n",
    "        resized_img = cv2.resize(cropped_img, (128,128))\n",
    "        crop_tensor = torch.from_numpy(resized_img.astype(np.float32) / 255.0).permute(2, 0, 1).unsqueeze(0)\n",
    "        return crop_tensor, fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed93ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.keypointnet import KeypointNet\n",
    "from utils.keypoints import map_keypoints_to_original\n",
    "\n",
    "\n",
    "def evaluate_model_on_dataset(obj_id):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    NUM_KEYPOINTS = 15\n",
    "    IMAGE_SIZE =(128, 128)\n",
    "    MODEL_PATH = BASE_PATH / f\"models/r6dnet/obj_{obj_id:06d}.pt\"\n",
    "    model = KeypointNet(\n",
    "        num_keypoints=NUM_KEYPOINTS,\n",
    "        output_size=IMAGE_SIZE,\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # test_images_dir = Path(f\"datasets/test/{obj_id:06d}/rgb\")\n",
    "    annotations_path = BASE_PATH / f\"data/annotations/test/{obj_id:06d}.json\"\n",
    "    keypoints_3D_path = BASE_PATH / f\"data/keypoints3d/{obj_id:06d}.json\"  # Adjust if needed\n",
    "\n",
    "    with open(annotations_path, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "\n",
    "    # Load 3D keypoints (for PnP)\n",
    "    with open(keypoints_3D_path, 'r') as f:\n",
    "        keypoints_3D = np.array(json.load(f)['keypoints_3D'])  # (N, 3)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for ann in tqdm(annotations, desc=\"Processing images\"):\n",
    "        image_id = ann[\"image_id\"]\n",
    "        image_path = BASE_PATH / ann[\"rgb_path\"]\n",
    "        camera_matrix = np.array(ann['K']).reshape(3, 3)  # (3, 3)\n",
    "        # bbox =  pad_bbox(ann['bbox_obj'])\n",
    "        R_gt = np.array(ann['rotation'])\n",
    "        t_gt = np.array(ann['translation'])\n",
    "\n",
    "        img, bbox = preprocess_image(image_path, obj_id, fallback=pad_bbox(ann['bbox_obj']))\n",
    "        img = img.to(device)\n",
    "\n",
    "        gt_keypoints_2D = np.array(ann['keypoints_2D'])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "\n",
    "        output = output.squeeze(0).cpu().numpy()  # (N, H, W)\n",
    "        # MSE between heatmaps (approximate by sum squared diff)\n",
    "        pred_heatmaps = output\n",
    "        pred_keypoints = decode_heatmaps(output)\n",
    "        pred_keypoints_orig = map_keypoints_to_original(pred_keypoints, bbox, IMAGE_SIZE)\n",
    "\n",
    "\n",
    "        # Assume ground truth heatmaps would be generated separately if needed (skip for now)\n",
    "        mse = np.mean(pred_heatmaps ** 2)\n",
    "\n",
    "   \n",
    "        mde = compute_mde(pred_keypoints_orig, gt_keypoints_2D)\n",
    "        pck = compute_pck(pred_keypoints_orig, gt_keypoints_2D, threshold=5.0)\n",
    "    \n",
    "\n",
    "        try:\n",
    "            rvec_pred, tvec_pred = estimate_pose_pnp(keypoints_3D, pred_keypoints_orig, camera_matrix)\n",
    "            R_pred, _ = cv2.Rodrigues(rvec_pred)\n",
    "            reproj_error = compute_reprojection_error(R_pred, tvec_pred, keypoints_3D, pred_keypoints_orig, camera_matrix)\n",
    "            add = compute_add(R_pred, tvec_pred, R_gt, t_gt, keypoints_3D)\n",
    "            adds = compute_adds(R_pred, tvec_pred, R_gt, t_gt, keypoints_3D)\n",
    "        except RuntimeError:\n",
    "            reproj_error = np.nan\n",
    "            add = np.nan\n",
    "            adds = np.nan\n",
    "\n",
    "\n",
    "             # Solve PnP\n",
    "        try:\n",
    "            rvec_pred_ransac, tvec_pred_ransac = estimate_pose_pnp_ransac(keypoints_3D, pred_keypoints_orig, camera_matrix, iterationsCount=5000, reprojectionError=20)\n",
    "            R_pred_ransac, _ = cv2.Rodrigues(rvec_pred_ransac)\n",
    "            reproj_error_ransac = compute_reprojection_error(R_pred_ransac, tvec_pred_ransac, keypoints_3D, pred_keypoints_orig, camera_matrix)\n",
    "            add_ransac = compute_add(R_pred_ransac, tvec_pred_ransac, R_gt, t_gt, keypoints_3D)\n",
    "            adds_ransac = compute_adds(R_pred_ransac, tvec_pred_ransac, R_gt, t_gt, keypoints_3D)\n",
    "        except RuntimeError:\n",
    "            reproj_error_ransac = np.nan\n",
    "            add_ransac = np.nan\n",
    "            adds_ransac = np.nan\n",
    "            \n",
    "        results.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"mse\": mse,\n",
    "            \"mde\": mde,\n",
    "            \"pck\": pck,\n",
    "            \"reproj_error\": reproj_error,\n",
    "            \"reproj_error_ransac\": reproj_error_ransac,\n",
    "            \"add\": add,\n",
    "            \"add_ransac\": add_ransac,\n",
    "            \"adds\": adds,\n",
    "            \"adds_ransac\": adds_ransac,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    avg_metrics = df.mean(numeric_only=True)\n",
    "\n",
    "    print(f\"Average metrics over test set:\\n{avg_metrics}\")\n",
    "\n",
    "    output_csv = Path(f\"results/{obj_id:06d}/test_metrics_yolo.csv\")\n",
    "    output_csv.parent.mkdir(exist_ok=True, parents=True)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved results to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b975f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 1220/1220 [00:48<00:00, 25.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics over test set:\n",
      "image_id                  609.500000\n",
      "mse                         0.027655\n",
      "mde                        20.125682\n",
      "pck                        36.907104\n",
      "reproj_error             2684.756534\n",
      "reproj_error_ransac        10.322645\n",
      "add                         1.593421\n",
      "add_ransac             136655.812803\n",
      "adds                        1.539570\n",
      "adds_ransac            136655.775942\n",
      "dtype: float64\n",
      "Saved results to results\\000011\\test_metrics_yolo.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "obj_id = 11\n",
    "evaluate_model_on_dataset(obj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19622c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775651f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae8e5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
