{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "parent_dir = os.path.abspath('../../')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from utils.heatmap import generate_multi_gaussian_heatmaps, decode_heatmaps\n",
    "from utils.image_handling import crop_image, pad_bbox\n",
    "from utils.keypoints import crop_and_resize_keypoints\n",
    "from utils.evaluation import compute_add, compute_adds, compute_mde, compute_pck, compute_reprojection_error, estimate_pose_pnp, estimate_pose_pnp_ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee1fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, bbox):\n",
    "    img = cv2.imread(str(image_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cropped_img = crop_image(img, bbox)\n",
    "    cropped_img = T.ToTensor()(cropped_img)\n",
    "    return cropped_img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# def preprocess_image_with_yolo(image_path):\n",
    "#     YOLO_MODEL_PATH = BASE_PATH / \"models/yolo/yolo-lm.pt\"\n",
    "#     yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "\n",
    "#     img = cv2.imread(str(image_path))\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     cropped_img = crop_image(img, bbox)\n",
    "#     cropped_img = T.ToTensor()(cropped_img)\n",
    "#     return cropped_img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed93ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.keypointnet import KeypointNet\n",
    "\n",
    "\n",
    "def evaluate_model_on_dataset(obj_id):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    NUM_KEYPOINTS = 15\n",
    "    IMAGE_SIZE =(128, 128)\n",
    "    MODEL_PATH = BASE_PATH / f\"models/r6dnet/obj_{obj_id:06d}.pt\"\n",
    "    model = KeypointNet(\n",
    "        num_keypoints=NUM_KEYPOINTS,\n",
    "        output_size=IMAGE_SIZE,\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # test_images_dir = Path(f\"datasets/test/{obj_id:06d}/rgb\")\n",
    "    annotations_path = BASE_PATH / f\"data/annotations/test/{obj_id:06d}.json\"\n",
    "    keypoints_3D_path = BASE_PATH / f\"data/keypoints3d/{obj_id:06d}.json\"  # Adjust if needed\n",
    "\n",
    "    with open(annotations_path, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "\n",
    "    # Load 3D keypoints (for PnP)\n",
    "    with open(keypoints_3D_path, 'r') as f:\n",
    "        keypoints_3D = np.array(json.load(f)['keypoints_3D'])  # (N, 3)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for ann in tqdm(annotations, desc=\"Processing images\"):\n",
    "        image_id = ann[\"image_id\"]\n",
    "        image_path = BASE_PATH / ann[\"rgb_path\"]\n",
    "        camera_matrix = np.array(ann['K']).reshape(3, 3)  # (3, 3)\n",
    "        bbox =  pad_bbox(ann['bbox_obj'])\n",
    "        gt_rotation = np.array(ann['rotation'])\n",
    "        R_gt, _ = cv2.Rodrigues(gt_rotation)\n",
    "        t_gt = np.array(ann['translation'])\n",
    "\n",
    "        img = preprocess_image(image_path, bbox=bbox).to(device)\n",
    "\n",
    "        gt_keypoints_2D = crop_and_resize_keypoints(np.array(ann['keypoints_2D']), bbox)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "\n",
    "        output = output.squeeze(0).cpu().numpy()  # (N, H, W)\n",
    "        # MSE between heatmaps (approximate by sum squared diff)\n",
    "        pred_heatmaps = output\n",
    "        pred_keypoints = decode_heatmaps(output)\n",
    "        # Assume ground truth heatmaps would be generated separately if needed (skip for now)\n",
    "        mse = np.mean(pred_heatmaps ** 2)\n",
    "\n",
    "        mde = compute_mde(pred_keypoints, gt_keypoints_2D)\n",
    "        pck = compute_pck(pred_keypoints, gt_keypoints_2D, threshold=5.0)\n",
    "\n",
    "        # Solve PnP\n",
    "        try:\n",
    "            rvec_pred, tvec_pred = estimate_pose_pnp(keypoints_3D, pred_keypoints, camera_matrix)\n",
    "            R_pred, _ = cv2.Rodrigues(rvec_pred)\n",
    "            reproj_error = compute_reprojection_error(rvec_pred, tvec_pred, keypoints_3D, gt_keypoints_2D, camera_matrix)\n",
    "            add = compute_add(R_pred, tvec_pred, R_gt, t_gt, keypoints_3D)\n",
    "            adds = compute_adds(R_pred, tvec_pred, R_gt, t_gt, keypoints_3D)\n",
    "        except RuntimeError:\n",
    "            reproj_error = np.nan\n",
    "            add = np.nan\n",
    "            adds = np.nan\n",
    "\n",
    "\n",
    "             # Solve PnP\n",
    "        try:\n",
    "            rvec_pred_ransac, tvec_pred_ransac = estimate_pose_pnp_ransac(keypoints_3D, pred_keypoints, camera_matrix)\n",
    "            R_pred_ransac, _ = cv2.Rodrigues(rvec_pred_ransac)\n",
    "            reproj_error_ransac = compute_reprojection_error(rvec_pred_ransac, tvec_pred_ransac, keypoints_3D, gt_keypoints_2D, camera_matrix)\n",
    "            add_ransac = compute_add(R_pred_ransac, tvec_pred_ransac, R_gt, t_gt, keypoints_3D)\n",
    "            adds_ransac = compute_adds(R_pred_ransac, tvec_pred_ransac, R_gt, t_gt, keypoints_3D)\n",
    "        except RuntimeError:\n",
    "            reproj_error_ransac = np.nan\n",
    "            add_ransac = np.nan\n",
    "            adds_ransac = np.nan\n",
    "\n",
    "        results.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"mse\": mse,\n",
    "            \"mde\": mde,\n",
    "            \"pck\": pck,\n",
    "            \"reproj_error\": reproj_error,\n",
    "            \"reproj_error_ransac\": reproj_error_ransac,\n",
    "            \"add\": add,\n",
    "            \"add_ransac\": add_ransac,\n",
    "            \"adds\": adds,\n",
    "            \"adds_ransac\": adds_ransac,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    avg_metrics = df.mean(numeric_only=True)\n",
    "\n",
    "    print(f\"Average metrics over test set:\\n{avg_metrics}\")\n",
    "\n",
    "    output_csv = Path(f\"results/{obj_id:06d}/test_metrics_gt.csv\")\n",
    "    output_csv.parent.mkdir(exist_ok=True, parents=True)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved results to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b975f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id = 1\n",
    "evaluate_model_on_dataset(obj_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
